{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sm_37',\n",
       " 'sm_50',\n",
       " 'sm_60',\n",
       " 'sm_61',\n",
       " 'sm_70',\n",
       " 'sm_75',\n",
       " 'sm_80',\n",
       " 'sm_86',\n",
       " 'compute_37']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_arch_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:0\n",
      "_CudaDeviceProperties(name='Quadro M4000', major=5, minor=2, total_memory=8192MB, multi_processor_count=13)\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for gpu_num in range(torch.cuda.device_count()):\n",
    "    print(f\"DEVICE:{gpu_num}\")\n",
    "    print(torch.cuda.get_device_properties(gpu_num))\n",
    "    print(torch.cuda.memory_summary(gpu_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated()=0\n",
      "torch.cuda.max_memory_allocated()=0\n",
      "torch.cuda.memory_reserved()=0\n",
      "torch.cuda.max_memory_reserved()=0\n",
      "torch.cuda.memory_cached()=0\n",
      "torch.cuda.max_memory_cached()=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUKE_SARGEN\\anaconda3\\envs\\pytorch110cu113\\lib\\site-packages\\torch\\cuda\\memory.py:384: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n",
      "C:\\Users\\LUKE_SARGEN\\anaconda3\\envs\\pytorch110cu113\\lib\\site-packages\\torch\\cuda\\memory.py:392: FutureWarning: torch.cuda.max_memory_cached has been renamed to torch.cuda.max_memory_reserved\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# print(f\"{torch.cuda.memory_snapshot()=}\")\n",
    "\n",
    "print(f\"{torch.cuda.memory_allocated()=}\")\n",
    "print(f\"{torch.cuda.max_memory_allocated()=}\")\n",
    "print(f\"{torch.cuda.memory_reserved()=}\")\n",
    "print(f\"{torch.cuda.max_memory_reserved()=}\")\n",
    "print(f\"{torch.cuda.memory_cached()=}\")\n",
    "print(f\"{torch.cuda.max_memory_cached()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active.all.allocated: 0\n",
      "active.all.current: 0\n",
      "active.all.freed: 0\n",
      "active.all.peak: 0\n",
      "active.large_pool.allocated: 0\n",
      "active.large_pool.current: 0\n",
      "active.large_pool.freed: 0\n",
      "active.large_pool.peak: 0\n",
      "active.small_pool.allocated: 0\n",
      "active.small_pool.current: 0\n",
      "active.small_pool.freed: 0\n",
      "active.small_pool.peak: 0\n",
      "active_bytes.all.allocated: 0\n",
      "active_bytes.all.current: 0\n",
      "active_bytes.all.freed: 0\n",
      "active_bytes.all.peak: 0\n",
      "active_bytes.large_pool.allocated: 0\n",
      "active_bytes.large_pool.current: 0\n",
      "active_bytes.large_pool.freed: 0\n",
      "active_bytes.large_pool.peak: 0\n",
      "active_bytes.small_pool.allocated: 0\n",
      "active_bytes.small_pool.current: 0\n",
      "active_bytes.small_pool.freed: 0\n",
      "active_bytes.small_pool.peak: 0\n",
      "allocated_bytes.all.allocated: 0\n",
      "allocated_bytes.all.current: 0\n",
      "allocated_bytes.all.freed: 0\n",
      "allocated_bytes.all.peak: 0\n",
      "allocated_bytes.large_pool.allocated: 0\n",
      "allocated_bytes.large_pool.current: 0\n",
      "allocated_bytes.large_pool.freed: 0\n",
      "allocated_bytes.large_pool.peak: 0\n",
      "allocated_bytes.small_pool.allocated: 0\n",
      "allocated_bytes.small_pool.current: 0\n",
      "allocated_bytes.small_pool.freed: 0\n",
      "allocated_bytes.small_pool.peak: 0\n",
      "allocation.all.allocated: 0\n",
      "allocation.all.current: 0\n",
      "allocation.all.freed: 0\n",
      "allocation.all.peak: 0\n",
      "allocation.large_pool.allocated: 0\n",
      "allocation.large_pool.current: 0\n",
      "allocation.large_pool.freed: 0\n",
      "allocation.large_pool.peak: 0\n",
      "allocation.small_pool.allocated: 0\n",
      "allocation.small_pool.current: 0\n",
      "allocation.small_pool.freed: 0\n",
      "allocation.small_pool.peak: 0\n",
      "inactive_split.all.allocated: 0\n",
      "inactive_split.all.current: 0\n",
      "inactive_split.all.freed: 0\n",
      "inactive_split.all.peak: 0\n",
      "inactive_split.large_pool.allocated: 0\n",
      "inactive_split.large_pool.current: 0\n",
      "inactive_split.large_pool.freed: 0\n",
      "inactive_split.large_pool.peak: 0\n",
      "inactive_split.small_pool.allocated: 0\n",
      "inactive_split.small_pool.current: 0\n",
      "inactive_split.small_pool.freed: 0\n",
      "inactive_split.small_pool.peak: 0\n",
      "inactive_split_bytes.all.allocated: 0\n",
      "inactive_split_bytes.all.current: 0\n",
      "inactive_split_bytes.all.freed: 0\n",
      "inactive_split_bytes.all.peak: 0\n",
      "inactive_split_bytes.large_pool.allocated: 0\n",
      "inactive_split_bytes.large_pool.current: 0\n",
      "inactive_split_bytes.large_pool.freed: 0\n",
      "inactive_split_bytes.large_pool.peak: 0\n",
      "inactive_split_bytes.small_pool.allocated: 0\n",
      "inactive_split_bytes.small_pool.current: 0\n",
      "inactive_split_bytes.small_pool.freed: 0\n",
      "inactive_split_bytes.small_pool.peak: 0\n",
      "max_split_size: -1\n",
      "num_alloc_retries: 0\n",
      "num_ooms: 0\n",
      "oversize_allocations.allocated: 0\n",
      "oversize_allocations.current: 0\n",
      "oversize_allocations.freed: 0\n",
      "oversize_allocations.peak: 0\n",
      "oversize_segments.allocated: 0\n",
      "oversize_segments.current: 0\n",
      "oversize_segments.freed: 0\n",
      "oversize_segments.peak: 0\n",
      "reserved_bytes.all.allocated: 0\n",
      "reserved_bytes.all.current: 0\n",
      "reserved_bytes.all.freed: 0\n",
      "reserved_bytes.all.peak: 0\n",
      "reserved_bytes.large_pool.allocated: 0\n",
      "reserved_bytes.large_pool.current: 0\n",
      "reserved_bytes.large_pool.freed: 0\n",
      "reserved_bytes.large_pool.peak: 0\n",
      "reserved_bytes.small_pool.allocated: 0\n",
      "reserved_bytes.small_pool.current: 0\n",
      "reserved_bytes.small_pool.freed: 0\n",
      "reserved_bytes.small_pool.peak: 0\n",
      "segment.all.allocated: 0\n",
      "segment.all.current: 0\n",
      "segment.all.freed: 0\n",
      "segment.all.peak: 0\n",
      "segment.large_pool.allocated: 0\n",
      "segment.large_pool.current: 0\n",
      "segment.large_pool.freed: 0\n",
      "segment.large_pool.peak: 0\n",
      "segment.small_pool.allocated: 0\n",
      "segment.small_pool.current: 0\n",
      "segment.small_pool.freed: 0\n",
      "segment.small_pool.peak: 0\n"
     ]
    }
   ],
   "source": [
    "for key, val in torch.cuda.memory_stats().items():\n",
    "    print(f\"{key}: {val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 GBb = 1024*1024*1024 bytes\n",
    "# torch.rand defaults to torch.float32 = 4 bytes\n",
    "# this creates a 1GB tensor and puts it on the cuda:0\n",
    "device = torch.device(\"cuda:0\")\n",
    "x = torch.rand(1, 256, 1024, 1024, requires_grad=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x\n",
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05264c394c9bf5c6ac8aaace9f814ed79d64a6d2d6f660c4b78d2e39382b8c09"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch19cu11': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
